{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 methods to implement autoencoder in tf 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x = np.concatenate((x_train, x_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "x = x.reshape((x.shape[0], -1))\n",
    "x = x.astype('float32') / 255.0\n",
    "\n",
    "trainloader = tf.data.Dataset.from_tensor_slices((x, x)).shuffle(70000).batch(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:04<00:37,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 2/10 [00:08<00:32,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▉                                                          | 3/10 [00:11<00:28,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:15<00:23,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.1085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:19<00:19,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:23<00:15,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:26<00:11,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:30<00:07,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.0998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:34<00:03,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:38<00:00,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:0.0978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First implementation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc = Sequential([\n",
    "            InputLayer(input_shape=(784)),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(2000, activation='relu'),\n",
    "            Dense(10),\n",
    "            ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.enc(x)\n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec = Sequential([\n",
    "            InputLayer(input_shape=(10)),\n",
    "            Dense(2000, activation='relu'),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(784, activation='sigmoid'),\n",
    "            ])\n",
    "\n",
    "    def call(self, z):\n",
    "        return self.dec(z)\n",
    "\n",
    "class AE(object):\n",
    "    def __init__(self):\n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "        self.optim = tf.keras.optimizers.Adam()\n",
    "            \n",
    "    def train(self):\n",
    "        for epoch in tqdm(range(10)):\n",
    "            epoch_loss = []\n",
    "            for x_batch, _ in trainloader:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    z = self.enc(x_batch)\n",
    "                    x_rec = self.dec(z)\n",
    "                    batch_loss = tf.keras.losses.BinaryCrossentropy()(x_batch, x_rec)\n",
    "                             \n",
    "                t_vars = self.enc.trainable_variables + self.dec.trainable_variables\n",
    "                enc_grads = tape.gradient(batch_loss, t_vars)\n",
    "                self.optim.apply_gradients(zip(enc_grads, t_vars))\n",
    "                epoch_loss.append(batch_loss) \n",
    "            print('epoch_loss:{:.4f}'.format(tf.reduce_mean(epoch_loss).numpy()))\n",
    "            \n",
    "ae = AE()\n",
    "ae.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2000)              22000     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 500)               1000500   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 784)               392784    \n",
      "=================================================================\n",
      "Total params: 3,330,794\n",
      "Trainable params: 3,330,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 0.2062\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1266\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1133\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1083\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1052\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1031\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1014\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1000\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.0988\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.0979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20de95bb988>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second implementation\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(2000, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(784, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy())\n",
    "model.fit(trainloader, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "274/274 [==============================] - 3s 11ms/step - loss: 0.2141\n",
      "Epoch 2/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1283\n",
      "Epoch 3/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1129\n",
      "Epoch 4/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1077\n",
      "Epoch 5/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1047\n",
      "Epoch 6/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1026\n",
      "Epoch 7/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.1009\n",
      "Epoch 8/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.0995\n",
      "Epoch 9/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.0985\n",
      "Epoch 10/10\n",
      "274/274 [==============================] - 2s 8ms/step - loss: 0.0975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20de94edb08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third implementation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "\n",
    "class AE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        self.enc = tf.keras.Sequential([\n",
    "            InputLayer(input_shape=(784,)),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(2000, activation='relu'),\n",
    "            Dense(10),\n",
    "        ])\n",
    "        \n",
    "        self.dec = tf.keras.Sequential([\n",
    "            InputLayer(input_shape=(10,)),\n",
    "            Dense(2000, activation='relu'),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(500, activation='relu'),\n",
    "            Dense(784, activation='sigmoid'),\n",
    "        ])\n",
    "          \n",
    "    def encode(self, x):\n",
    "        return self.enc(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.dec(z)\n",
    "    \n",
    "    def call(self, x): \n",
    "        z = self.enc(x) \n",
    "        return self.dec(z)\n",
    "\n",
    "ae = AE() \n",
    "ae.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy())\n",
    "ae.fit(trainloader, epochs=10, verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
